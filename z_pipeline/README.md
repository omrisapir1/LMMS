# z_pipeline

`z_pipeline` implements a two-phase training pipeline that converts latent reasoning traces into a discrete language of Z tokens, and then trains a language model to generate and reason using those Z tokens autoregressively.

The pipeline assumes a prior Phase-1 latent-reasoning model and builds directly on top of it.

---

## Background: Coconut / Latent Execution (Phase-1)

Before `z_pipeline` starts, the model has already gone through a Coconut-style latent execution phase (Phase-1).

In Phase-1:
- The model reasons using latent tokens (not real text tokens)
- Each `\u003cLATENT\u003e` token is replaced by a hidden state from the previous position
- The model eventually predicts an `\u003cANSWER\u003e` token
- A digit head predicts the final numeric answer from the `\u003cANSWER\u003e` hidden state
- The trained Phase-1 model is saved to disk

`z_pipeline` starts from this saved Phase-1 model.

---

## Dataset Origin and Contract

The dataset used by both Phase-2 and Phase-3 is generated by the Phase-1 model itself.

Specifically:
- The Phase-1 model is run on a large set of questions
- For each question, the model executes latent reasoning
- The hidden states produced at each latent step are recorded
- Only correctly answered examples are kept

This produces the dataset consumed by `z_pipeline`.

### Final Dataset Schema (Fixed)

```text
question: str
latent_states: [K, H]
answer_digits: [5]
num_latents: K
```

Notes:
- `latent_states` are pre-truncated to exactly `K`
- There is no extra latent state for `\u003cANSWER\u003e`
- `latent_states[k]` is the latent reasoning state that should produce `Z_{k+1}`
- `answer_digits` is a 5-digit, MSB-first representation of the correct answer
- This contract is fixed and shared across phases.

## High-Level Pipeline Overview

```
Phase-1 (Latent / Coconut)  ──▶  Dataset
                                  │
                                  ▼
                       Phase-2: Learn Z tokens
                                  │
                                  ▼
                 Phase-3: SFT with Z tokens (generate)
                                  │
                                  ▼
                   Autoregressive Z + \u003cANSWER\u003e
                                  │
                                  ▼
                    Digit prediction (final eval)
```

## Phase-2: Learn Z Tokens from Latent States

### Goal

Learn a discrete alphabet of Z tokens aligned to latent reasoning states. Phase-2 discovers a discrete representation of latent reasoning that can later be generated as normal tokens.

### What Phase-2 Does

- Loads the saved Phase-1 model
- Expands the tokenizer with a new vocabulary of Z tokens: `\u003cZ_0\u003e ... \u003cZ_{V-1}\u003e`
- Resizes the LLM embedding layer to include Z tokens (Z embeddings are part of the LLM embedding matrix, not a separate table)
- Learns:
  - Z token embeddings (rows in the LLM embedding layer)
  - Z selector: a linear map from latent state → Z distribution
- Keeps the rest of the LLM frozen
- Uses only digit prediction loss for supervision
- No text generation is performed in Phase-2

### Z Selection Mechanism

For each latent state `h_k ∈ R^H`:

```
logits_k = W_selector(h_k)          # shape [V]
probs_k  = softmax(logits_k / tau)
```

- Training: soft mixtures of Z embeddings are used
- Evaluation: `argmax(probs_k)` is used
- Phase-2 explicitly trains with soft assignments but evaluates with argmax to match Phase-3 behavior

### Latent → Z Mapping

- `latent_states[0]` → predicts `Z_1`
- `latent_states[1]` → predicts `Z_2`
- …
- `latent_states[K-1]` → predicts `Z_K`

There is no Z corresponding to `\u003cANSWER\u003e` in Phase-2.

### Temperature Annealing

- Z selector logits are divided by a temperature `tau`
- `tau` is annealed to near-zero
- Early training encourages exploration
- Final training approximates discrete argmax behavior

### Digit Imbalance Handling

The dataset contains many answers with trailing zeros, which can bias learning. Phase-2 includes digit imbalance handling:

- Zero digits are probabilistically dropped from the loss
- Non-zero digits are always included
- Drop rates are derived from dataset statistics

This prevents trivial shortcuts and forces Z tokens to encode meaningful information.

### Trainable vs Frozen (Phase-2)

Trainable:
- Z token embedding rows (in the LLM embedding matrix)
- Z selector parameters

Frozen:
- Base LLM parameters
- Digit heads
- Non-Z token embeddings

### Phase-2 Evaluation

- Uses argmax Z selection
- Measures digit exact-match accuracy
- Used only for diagnostics and early stopping (Phase-2 metrics are not the final objective)

## Phase-3: SFT with Z Tokens

### Goal

Train the model to generate Z tokens autoregressively as a real language. Phase-3 is the phase that matters for final evaluation.

### Dataset Construction for Phase-3

Phase-3 uses the same dataset as Phase-2. To build Phase-3 training inputs:

1. Take each Phase-2 example: `Question + \u003cLATENT\u003e * K + \u003cANSWER\u003e`
2. Use the Phase-2-trained model to convert latent states into Z tokens (argmax): `latent_states → Z_1, Z_2, ..., Z_K`
3. Construct: `Question + Z_1 + Z_2 + ... + Z_K + \u003cANSWER\u003e`

This conversion is deterministic and uses the in-memory Phase-2 model.

### What Phase-3 Does

- Continues in memory from the Phase-2-trained model
- Uses standard supervised fine-tuning (SFT)
- Trains the model to generate Z tokens autoregressively
- Predicts `\u003cANSWER\u003e` to terminate generation
- Uses digit heads to compute final correctness

### Generation Behavior (Phase-3)

- Z tokens are generated autoregressively
- `\u003cANSWER\u003e` acts as EOS
- Generation stops when `\u003cANSWER\u003e` is produced
- Final answer digits are predicted from the `\u003cANSWER\u003e` hidden state
- Evaluation uses standard `.generate()`

### Restricted Vocabulary in Phase-3

In Phase-3, the LM head is restricted. Only rows corresponding to:

- `\u003cZ_0\u003e ... \u003cZ_{V-1}\u003e`
- `\u003cANSWER\u003e`

are active. All other token logits are masked or removed. This ensures the model can only generate Z tokens and `\u003cANSWER\u003e`, enforcing the discrete reasoning language.

### Trainable vs Frozen (Phase-3)

Trainable:
- Z token embeddings
- Z token LM-head rows
- `\u003cANSWER\u003e` LM-head row

Frozen initially:
- All other LLM parameters
- Digit heads (unless explicitly unfrozen later)

### Phase-2 → Phase-3 Handoff

- There is no disk checkpoint between phases
- Phase-3 starts directly from the in-memory Phase-2 model
- Z embeddings and learned alignment are reused immediately
- This guarantees exact consistency between phases

## Folder Structure

```
z_pipeline/
├── shared/        # utilities, loaders, tokenizer helpers
├── phase2/        # learn Z tokens from latent states
├── pipeline/      # orchestration (run_experiment.py)
└── README.md
```

Note: The Phase-3 logic is described above; its orchestration lives under `pipeline/` in this repository layout.

## What Comes Next

After Phase-3:
- Reasoning is fully discrete
- Z tokens are part of the generation vocabulary
- The model reasons using `.generate()`

This enables the next stage:

- Phase-4: Reinforcement Learning (PPO / GRPO) on Z-token reasoning
